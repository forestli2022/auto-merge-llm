strategy: fold_gmm_cluster
global_params:
  random_seed: 0
  cache_dir: "/mnt/ccnas2/tdp/fl1123/.cache/auto-merge-llm-cache"
  output_path: "/mnt/ccnas2/bdp/fl1123/code/auto-merge-llm/output/fold_gmm_cluster_7b"
  load_run_history: true
  evaluation:
    in_memory: false
    vllm: false
    enforce_eager: true
    batch_size: 4
    torch_dtype: float16
    limit: 500
    device: "cuda"
    tasks:
      - task: piqa
        metric: "acc,none"
        test_split: train
      - task: wsc
        metric: "acc,none"
        test_split: train
      - task: commonsense_qa
        metric: "acc,none"
        test_split: train
      - task: mmlu
        metric: "acc,none"
        test_split: validation
    final_evaluation_tasks:
      - task: piqa
        metric: "acc,none"
      - task: wsc
        metric: "acc,none"
      - task: commonsense_qa
        metric: "acc,none"
      - task: boolq
        metric: "acc,none"
      - task: mmlu
        metric: "acc,none"
      - task: race
        metric: "acc,none"
      - task: hellaswag
        metric: "acc,none"

strategies:
  normal_models: !include normal_models.yaml
  normal_slices: !include normal_slices.yaml
  lfs: !include lfs.yaml
  dis: !include dis.yaml
  fold_gmm_cluster: !include fold_gmm_7b.yaml