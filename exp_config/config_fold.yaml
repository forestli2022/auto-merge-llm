strategy: fold
global_params:
  random_seed: 0
  cache_dir: "/mnt/ccnas2/tdp/fl1123/.cache/auto-merge-llm-cache"
  #load_run_history: None
  output_path: "/mnt/ccnas2/bdp/fl1123/code/auto-merge-llm/output/fold"
  evaluation:
    in_memory: false
    vllm: false
    enforce_eager: true
    batch_size: 2
    torch_dtype: float16
    #num_fewshot: None
    #limit: 10  # Limit the number of examples per task (for debug). 
    device: "cuda"
    include_path: ""
    tasks:
      - task: piqa
        metric: "acc,none"
        test_split: train
      - task: wsc
        metric: "acc,none"
        test_split: train
      - task: commonsense_qa
        metric: "acc,none"
        test_split: train
      - task: mmlu
        metric: "acc,none"
        test_split: validation
strategies:
  normal_models: !include normal_models.yaml
  normal_slices: !include normal_slices.yaml
  lfs: !include lfs.yaml
  dis: !include dis.yaml
  prune: !include prune.yaml
  fold: !include fold.yaml